{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1493d6bd-0e19-420a-b63a-83df30f82cc9",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730a553a-0c6f-4ee3-a63d-b71cdcf4c121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Classes for tokenization and model training\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer)\n",
    "\n",
    "# Import DatasetDict which will help us prepare our own dataset for use in training and evaulating machine learning models\n",
    "from datasets import DatasetDict\n",
    "\n",
    "# Import function to be used as loss function\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c31ef-20ad-49d2-b766-365cdd6db40f",
   "metadata": {},
   "source": [
    "# Prepare Dataset for Confirmatory Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ceeeea-ba8b-4750-bf69-567f012ce842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DatasetDict object we created in the previous notebook. \n",
    "datadict = DatasetDict.load_from_disk('../data/ellipse.hf/')\n",
    "\n",
    "# We are specifically interested in using the test set since we are in our model evaluation phase\n",
    "ds = datadict['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1af32978-fdd7-4ef6-93db-adaa444b4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/both_raters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e47da2-a192-4fbe-9e89-ff0955f2d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = pd.DataFrame({\n",
    "    \"text_id_original\": ds[\"text_id\"],\n",
    "    \"order\": range(ds.num_rows)\n",
    "})\n",
    "df = pd.merge(idf, df, on=\"text_id_original\").sort_values(\"order\").drop(\"order\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "650dd1c1-4300-429c-b16f-7c5cf7b63fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Model inference pipeline that uses our finetuned model\n",
    "def predict(eval_data, model_path):\n",
    "    pipe = pipeline('text-classification',\n",
    "                    model=model_path,\n",
    "                    truncation=True,\n",
    "                    batch_size=16,\n",
    "                    function_to_apply='none',\n",
    "                   )\n",
    "    \n",
    "    predictions = [pipe(text)[0]['score'] for text in tqdm(eval_data['text'])]\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e053299-ef81-4d1c-b069-cfff22d10cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27171471956f49759898fc74e3cfd530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4a931e95b848b28f8821653b1f4140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76991ed84fbf48d69ae1fa8e5fda6ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path_dict = {\n",
    "    \"bert\": \"../bin/Grammar-bert-base-uncased/checkpoint-852\",\n",
    "    \"deberta\": \"../bin/Grammar-microsoft/deberta-base/checkpoint-284\",\n",
    "    \"xlm\": \"../bin/Grammar-xlm-roberta-base/checkpoint-852\",\n",
    "}\n",
    "\n",
    "for model_name, model_path in model_path_dict.items():\n",
    "    df[model_name] = predict(ds, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5665aeb3-40f7-40db-a945-5ab1bcf7a5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text_id_original', 'Filename', 'Text', 'Overall_1', 'Cohesion_1',\n",
       "       'Syntax_1', 'Vocabulary_1', 'Phraseology_1', 'Grammar_1',\n",
       "       'Conventions_1', 'Identifying_Info_1', 'Overall_2', 'Cohesion_2',\n",
       "       'Syntax_2', 'Vocabulary_2', 'Phraseology_2', 'Grammar_2',\n",
       "       'Conventions_2', 'Identifying_Info_2', 'text_id_kaggle', 'bert',\n",
       "       'deberta', 'xlm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b603ae8a-59aa-435a-bbff-90534a05a053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../results/ensemble-cfa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4b09d4-61a6-4fcc-8a76-3663f6d326c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hf]",
   "language": "python",
   "name": "conda-env-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
