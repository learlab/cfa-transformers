{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1493d6bd-0e19-420a-b63a-83df30f82cc9",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "In this notebook, we will train 2 models using the best hyperparameters for this dataset.\n",
    "\n",
    "We will continue to use the wandb library to track our training runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730a553a-0c6f-4ee3-a63d-b71cdcf4c121",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_ENTITY=langdon\n",
      "env: WANDB_PROJECT=ellipse\n",
      "env: WANDB_DIR=/home/jovyan/active-projects/ellipse-methods-showcase/bin\n"
     ]
    }
   ],
   "source": [
    "# Import Classes for tokenization and model training\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer)\n",
    "\n",
    "# Import DatasetDict which will help us prepare our own dataset for use in training and evaulating machine learning models\n",
    "from datasets import DatasetDict\n",
    "\n",
    "# Import function to be used as loss function\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import library to track our training runs and change settings\n",
    "import wandb\n",
    "\n",
    "# Replace the variables below with your own: name, project name, and project directory\n",
    "%env WANDB_ENTITY = langdon\n",
    "%env WANDB_PROJECT = ellipse\n",
    "%env WANDB_DIR = /home/jovyan/active-projects/ellipse-methods-showcase/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177080b1-2717-4ae0-b856-f72844c625eb",
   "metadata": {},
   "source": [
    "## Load DatasetDict and Tokenize\n",
    "\n",
    "We could have tokenized our datadict when we created the dataset partitions, but waiting until the last minute gives us the flexibility to try out different models that may require different tokenization schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9e764f-e78c-412c-b04a-dd91968dc978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize tokenizer and create helper function for tokenization as we did in the previous notebooks.\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_inputs(example):\n",
    "    return tokenizer(example['text'], max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a87615f-8e33-45a8-b10d-daf0812d4b20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_datadict(score_to_predict):\n",
    "    ''' Selects a target score that the model should predict and renames that score to 'label'.\n",
    "    Removes other columns from the dataset. The other columns are not needed for training.\n",
    "    '''\n",
    "    \n",
    "    # These columns will be removed from the dataset\n",
    "    scores = {\n",
    "        'Overall',\n",
    "        'Cohesion',\n",
    "        'Syntax',\n",
    "        'Vocabulary',\n",
    "        'Phraseology',\n",
    "        'Grammar',\n",
    "        'Conventions'\n",
    "    }\n",
    "    \n",
    "    columns_to_remove = scores.symmetric_difference([score_to_predict])\n",
    "    \n",
    "    # Load the DatasetDict object we created in the previous notebook. \n",
    "    # We will be removing the columns that we defined above, and renaming the target column (=score_to_predict) into 'label'\n",
    "    dd = (DatasetDict\n",
    "          .load_from_disk('../data/ellipse.hf')\n",
    "          .remove_columns(columns_to_remove)\n",
    "          .map(tokenize_inputs, remove_columns=['text_id', 'text']) # the transformer does not need these columns to train.\n",
    "          .rename_column(score_to_predict, 'label') # Huggingface will look for a column that contains the string 'label' to calculate metrics.\n",
    "         )\n",
    "    \n",
    "    return dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3346da08-38c8-440d-a0ef-27759050db9d",
   "metadata": {},
   "source": [
    "## Compute Metric\n",
    "\n",
    "By default, Huggingface will evaluate models based on the sum of metrics produced by this function.\n",
    "\n",
    "We only have one metric (mse), but if other metrics are included (like r-squared), Huggingface needs to know which metric to use (because MSE should be minimized and r-squared should be maximized, summing these values will create a nonsense metric). We will be specifying th metric when we are configuring the training arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b56260e-022b-4655-abdc-8324332ae0c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    mse = mean_squared_error(labels, preds)\n",
    "\n",
    "    return {'mse': mse}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27719516-3918-44b6-b734-b9599b9e4a31",
   "metadata": {},
   "source": [
    "## Train Function\n",
    "\n",
    "We can make some improvements here. The development data is more-or-less wasted with this configuration, so we could either decide not to use it, or we could utilize it by keeping the best model from 4-5 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aef09b1-3ce9-42ff-ad4c-a60ea6ec9266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(score_to_predict):\n",
    "    # load in the dataset we created before with the target column's name changed to 'label'\n",
    "    datadict = get_datadict(score_to_predict)\n",
    "\n",
    "    # Generate in-fold and out-of-fold indexes\n",
    "    folds = ShuffleSplit(n_splits=5, random_state=42)        \n",
    "    splits = folds.split(np.zeros(datadict[\"train\"].num_rows), datadict[\"train\"][\"label\"])\n",
    "    \n",
    "    # Iterate over in-fold and out-of-fold indexes\n",
    "    for i, (inf_idxs, oof_idxs) in enumerate(splits):\n",
    "        # since we create the model from_pretrained() within the train() function, we do not need a model_init()\n",
    "        model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = '../bin/checkpoints',\n",
    "            optim = 'adamw_torch',\n",
    "            logging_dir = f'../logs/{score_to_predict}',\n",
    "            evaluation_strategy='epoch',\n",
    "            save_strategy='no',\n",
    "            log_level='error',\n",
    "            disable_tqdm = False,\n",
    "            report_to='wandb',\n",
    "            num_train_epochs=2, # tuned\n",
    "            learning_rate=5e-5, # tuned\n",
    "            per_device_train_batch_size=16, # tuned\n",
    "            per_device_eval_batch_size=16,\n",
    "        )\n",
    "    \n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=datadict['train'].select(inf_idxs),\n",
    "            eval_dataset=datadict['train'].select(oof_idxs),\n",
    "            compute_metrics=compute_metrics,\n",
    "            tokenizer=tokenizer,\n",
    "        )\n",
    "    \n",
    "        trainer.train()\n",
    "        trainer.save_model(f'../bin/kfold-{score_to_predict.lower()}-models/{score_to_predict.lower()}-model-{i:02}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ca5e4-f0b5-4255-b0e3-70001d125a07",
   "metadata": {},
   "source": [
    "## Train Grammar\n",
    "\n",
    "Finetune a model that predicts the 'Grammar' scores in the ELLIPSE corpus using the function we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "943296c0-bc44-4bec-ab9c-80c7269ff12d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a39cc171d3840c0ba6e712ada26a719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4537 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8fd104851b437b85b8547aea5e0543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee7970f2b6c48b282b2b2c22fa62b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/973 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlangdon\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/ellipse-methods-showcase/bin/wandb/run-20231013_023707-bb1shv9l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/langdon/ellipse/runs/bb1shv9l' target=\"_blank\">trim-flower-66</a></strong> to <a href='https://wandb.ai/langdon/ellipse' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/langdon/ellipse' target=\"_blank\">https://wandb.ai/langdon/ellipse</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/langdon/ellipse/runs/bb1shv9l' target=\"_blank\">https://wandb.ai/langdon/ellipse/runs/bb1shv9l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='512' max='512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [512/512 03:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.276915</td>\n",
       "      <td>0.276915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.322500</td>\n",
       "      <td>0.272244</td>\n",
       "      <td>0.272244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='512' max='512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [512/512 03:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247370</td>\n",
       "      <td>0.247370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.372600</td>\n",
       "      <td>0.250730</td>\n",
       "      <td>0.250730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='512' max='512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [512/512 03:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.303360</td>\n",
       "      <td>0.303360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.358800</td>\n",
       "      <td>0.242446</td>\n",
       "      <td>0.242446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='512' max='512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [512/512 03:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.265568</td>\n",
       "      <td>0.265568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.360500</td>\n",
       "      <td>0.256617</td>\n",
       "      <td>0.256617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='512' max='512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [512/512 03:43, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.351895</td>\n",
       "      <td>0.351895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.355300</td>\n",
       "      <td>0.256412</td>\n",
       "      <td>0.256412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train('Grammar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed367c-583c-4acd-a0ed-599694e6eb19",
   "metadata": {},
   "source": [
    "## Train Vocabulary\n",
    "\n",
    "We can use the same approach to finetune a model that predicts the 'Vocabulary' scores. We will assume that the optimal hyperparameters are similar for different scores on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "267b472f-34cb-4c26-87a6-648e24e6fa07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bffbf84780043c1a7d091f673331a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4537 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e911836f4dc43e8b7c8143edf2ffccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f46d9df31a48f5b8c46daef593a2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/973 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='512' max='512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [512/512 03:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.199172</td>\n",
       "      <td>0.199172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.189354</td>\n",
       "      <td>0.189354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='512' max='512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [512/512 03:43, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.213810</td>\n",
       "      <td>0.213810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.305200</td>\n",
       "      <td>0.191467</td>\n",
       "      <td>0.191467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='512' max='512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [512/512 03:43, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.204694</td>\n",
       "      <td>0.204694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.306300</td>\n",
       "      <td>0.194940</td>\n",
       "      <td>0.194940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='512' max='512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [512/512 03:43, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.365828</td>\n",
       "      <td>0.365828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>0.209755</td>\n",
       "      <td>0.209755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='512' max='512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [512/512 03:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.195263</td>\n",
       "      <td>0.195263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.316300</td>\n",
       "      <td>0.191075</td>\n",
       "      <td>0.191075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train('Vocabulary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c31ef-20ad-49d2-b766-365cdd6db40f",
   "metadata": {},
   "source": [
    "# Prepare Dataset for Confirmatory Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77ceeeea-ba8b-4750-bf69-567f012ce842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DatasetDict object we created in the previous notebook. \n",
    "datadict = DatasetDict.load_from_disk('../data/ellipse.hf/')\n",
    "\n",
    "# We are specifically interested in using the test set since we are in our model evaluation phase\n",
    "ds = datadict['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1af32978-fdd7-4ef6-93db-adaa444b4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/both_raters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9e47da2-a192-4fbe-9e89-ff0955f2d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = pd.DataFrame({\n",
    "    \"text_id_original\": ds[\"text_id\"],\n",
    "    \"order\": range(ds.num_rows)\n",
    "})\n",
    "df = pd.merge(idf, df, on=\"text_id_original\").sort_values(\"order\").drop(\"order\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "650dd1c1-4300-429c-b16f-7c5cf7b63fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Model inference pipeline that uses our finetuned model\n",
    "def predict(eval_data, model_path):\n",
    "    pipe = pipeline('text-classification',\n",
    "                    model=model_path,\n",
    "                    truncation=True,\n",
    "                    batch_size=16,\n",
    "                    function_to_apply='none',\n",
    "                   )\n",
    "    \n",
    "    predictions = [pipe(text)[0]['score'] for text in tqdm(eval_data['text'])]\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e053299-ef81-4d1c-b069-cfff22d10cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bb845de03d4c10abb5b3ae8c70fa7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e856f15a8e3f4187b7309c89cdb76766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ab056e4a2049b4ba59c5478cf806fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b873a4be1386461596aaa9bf7ae52f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34050f7eacb9431caade1e571d426b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f70acee9774c3880f27365507a3d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b13b5a6a214420381c4c3e33b5a04d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61296a974b9f427a885037bcf78efb70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca395c37b2c4488854c17dfed2c6f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53343f7e24284d1ea1341cb39a994176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for score_to_predict in [\"grammar\", \"vocabulary\"]:\n",
    "    for i in range(5):\n",
    "        model_path = f\"../bin/kfold-{score_to_predict}-models/{score_to_predict}-model-{i:02}\"\n",
    "        df[f\"{score_to_predict}-model-{i}\"] = predict(ds, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5665aeb3-40f7-40db-a945-5ab1bcf7a5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id_original</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>Overall_1</th>\n",
       "      <th>Cohesion_1</th>\n",
       "      <th>Syntax_1</th>\n",
       "      <th>Vocabulary_1</th>\n",
       "      <th>Phraseology_1</th>\n",
       "      <th>Grammar_1</th>\n",
       "      <th>Conventions_1</th>\n",
       "      <th>...</th>\n",
       "      <th>grammar-model-0</th>\n",
       "      <th>grammar-model-1</th>\n",
       "      <th>grammar-model-2</th>\n",
       "      <th>grammar-model-3</th>\n",
       "      <th>grammar-model-4</th>\n",
       "      <th>vocabulary-model-0</th>\n",
       "      <th>vocabulary-model-1</th>\n",
       "      <th>vocabulary-model-2</th>\n",
       "      <th>vocabulary-model-3</th>\n",
       "      <th>vocabulary-model-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAUUP138190003116482836_OR</td>\n",
       "      <td>AAAUUP138190003116482836_OR.txt</td>\n",
       "      <td>The famous Albert Einstein always said \"Imagin...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3.945891</td>\n",
       "      <td>3.906997</td>\n",
       "      <td>3.874162</td>\n",
       "      <td>3.937964</td>\n",
       "      <td>3.877669</td>\n",
       "      <td>3.740423</td>\n",
       "      <td>3.747329</td>\n",
       "      <td>3.594682</td>\n",
       "      <td>3.608412</td>\n",
       "      <td>3.749964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAUUP138190002068932807_OR</td>\n",
       "      <td>AAAUUP138190002068932807_OR.txt</td>\n",
       "      <td>People these days dont go outdoors as much as ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4.177153</td>\n",
       "      <td>4.026624</td>\n",
       "      <td>4.047930</td>\n",
       "      <td>4.220422</td>\n",
       "      <td>4.240192</td>\n",
       "      <td>3.710368</td>\n",
       "      <td>3.769626</td>\n",
       "      <td>3.544382</td>\n",
       "      <td>3.738004</td>\n",
       "      <td>3.874523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAXMP138200002018982823_OR</td>\n",
       "      <td>AAAXMP138200002018982823_OR.txt</td>\n",
       "      <td>One of the things I want to acumplish in the f...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4.003042</td>\n",
       "      <td>3.524597</td>\n",
       "      <td>3.769304</td>\n",
       "      <td>3.703856</td>\n",
       "      <td>3.969286</td>\n",
       "      <td>3.273657</td>\n",
       "      <td>3.245494</td>\n",
       "      <td>3.113843</td>\n",
       "      <td>3.362435</td>\n",
       "      <td>3.353452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAUUP138180000043802140_OR</td>\n",
       "      <td>AAAUUP138180000043802140_OR.txt</td>\n",
       "      <td>I think that success, are composed by failures...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.944404</td>\n",
       "      <td>3.125247</td>\n",
       "      <td>3.005486</td>\n",
       "      <td>2.804622</td>\n",
       "      <td>2.910588</td>\n",
       "      <td>3.406393</td>\n",
       "      <td>3.464580</td>\n",
       "      <td>3.456613</td>\n",
       "      <td>3.629762</td>\n",
       "      <td>3.518577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAXMP138190000364752108_OR</td>\n",
       "      <td>AAAXMP138190000364752108_OR.txt</td>\n",
       "      <td>Which be the characteristic that show a person...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.211505</td>\n",
       "      <td>2.137684</td>\n",
       "      <td>2.233499</td>\n",
       "      <td>2.097087</td>\n",
       "      <td>2.239886</td>\n",
       "      <td>2.730236</td>\n",
       "      <td>2.829128</td>\n",
       "      <td>2.726695</td>\n",
       "      <td>2.693180</td>\n",
       "      <td>2.789509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>AAAUUP138180000261162117_OR</td>\n",
       "      <td>AAAUUP138180000261162117_OR.txt</td>\n",
       "      <td>I believe music, drama, or art class should be...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4.047146</td>\n",
       "      <td>4.007442</td>\n",
       "      <td>4.117114</td>\n",
       "      <td>4.191662</td>\n",
       "      <td>3.901466</td>\n",
       "      <td>4.106008</td>\n",
       "      <td>3.950391</td>\n",
       "      <td>4.156456</td>\n",
       "      <td>4.176138</td>\n",
       "      <td>4.182713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>AAAXMP138190000094922128_OR</td>\n",
       "      <td>AAAXMP138190000094922128_OR.txt</td>\n",
       "      <td>Some schools in different states in America th...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3.380976</td>\n",
       "      <td>3.192650</td>\n",
       "      <td>3.298422</td>\n",
       "      <td>3.492209</td>\n",
       "      <td>3.353168</td>\n",
       "      <td>3.253963</td>\n",
       "      <td>3.284392</td>\n",
       "      <td>3.280299</td>\n",
       "      <td>3.130947</td>\n",
       "      <td>3.180582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>AAAXMP138190000120882107_OR</td>\n",
       "      <td>AAAXMP138190000120882107_OR.txt</td>\n",
       "      <td>First impressions are always important and can...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.586772</td>\n",
       "      <td>3.680668</td>\n",
       "      <td>3.855306</td>\n",
       "      <td>4.028326</td>\n",
       "      <td>3.781683</td>\n",
       "      <td>3.617156</td>\n",
       "      <td>3.583234</td>\n",
       "      <td>3.596291</td>\n",
       "      <td>3.813251</td>\n",
       "      <td>3.465148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>AAAXMP138200001632912845_OR</td>\n",
       "      <td>AAAXMP138200001632912845_OR.txt</td>\n",
       "      <td>Why is honesty important for you?\\r\\n\\r\\nI thi...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.413828</td>\n",
       "      <td>2.485096</td>\n",
       "      <td>2.318097</td>\n",
       "      <td>2.371035</td>\n",
       "      <td>2.304187</td>\n",
       "      <td>2.422342</td>\n",
       "      <td>2.475149</td>\n",
       "      <td>2.417537</td>\n",
       "      <td>2.380605</td>\n",
       "      <td>2.596770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>AAAUUP138190003282472139_OR</td>\n",
       "      <td>AAAUUP138190003282472139_OR.txt</td>\n",
       "      <td>Selecting me as one of the students that can v...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.324507</td>\n",
       "      <td>3.256163</td>\n",
       "      <td>3.232590</td>\n",
       "      <td>3.099558</td>\n",
       "      <td>3.287645</td>\n",
       "      <td>3.469777</td>\n",
       "      <td>3.537421</td>\n",
       "      <td>3.303370</td>\n",
       "      <td>3.414260</td>\n",
       "      <td>3.420581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>973 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                text_id_original                         Filename  \\\n",
       "0    AAAUUP138190003116482836_OR  AAAUUP138190003116482836_OR.txt   \n",
       "1    AAAUUP138190002068932807_OR  AAAUUP138190002068932807_OR.txt   \n",
       "2    AAAXMP138200002018982823_OR  AAAXMP138200002018982823_OR.txt   \n",
       "3    AAAUUP138180000043802140_OR  AAAUUP138180000043802140_OR.txt   \n",
       "4    AAAXMP138190000364752108_OR  AAAXMP138190000364752108_OR.txt   \n",
       "..                           ...                              ...   \n",
       "968  AAAUUP138180000261162117_OR  AAAUUP138180000261162117_OR.txt   \n",
       "969  AAAXMP138190000094922128_OR  AAAXMP138190000094922128_OR.txt   \n",
       "970  AAAXMP138190000120882107_OR  AAAXMP138190000120882107_OR.txt   \n",
       "971  AAAXMP138200001632912845_OR  AAAXMP138200001632912845_OR.txt   \n",
       "972  AAAUUP138190003282472139_OR  AAAUUP138190003282472139_OR.txt   \n",
       "\n",
       "                                                  Text  Overall_1  Cohesion_1  \\\n",
       "0    The famous Albert Einstein always said \"Imagin...          4           4   \n",
       "1    People these days dont go outdoors as much as ...          3           3   \n",
       "2    One of the things I want to acumplish in the f...          2           2   \n",
       "3    I think that success, are composed by failures...          3           4   \n",
       "4    Which be the characteristic that show a person...          2           2   \n",
       "..                                                 ...        ...         ...   \n",
       "968  I believe music, drama, or art class should be...          4           4   \n",
       "969  Some schools in different states in America th...          4           3   \n",
       "970  First impressions are always important and can...          4           4   \n",
       "971  Why is honesty important for you?\\r\\n\\r\\nI thi...          2           2   \n",
       "972  Selecting me as one of the students that can v...          3           4   \n",
       "\n",
       "     Syntax_1  Vocabulary_1  Phraseology_1  Grammar_1  Conventions_1  ...  \\\n",
       "0           3             4              4          4              4  ...   \n",
       "1           3             3              3          3              3  ...   \n",
       "2           2             3              3          3              3  ...   \n",
       "3           3             3              3          4              3  ...   \n",
       "4           2             3              2          2              3  ...   \n",
       "..        ...           ...            ...        ...            ...  ...   \n",
       "968         4             4              4          4              4  ...   \n",
       "969         3             4              4          4              4  ...   \n",
       "970         4             4              4          4              5  ...   \n",
       "971         2             2              2          2              2  ...   \n",
       "972         3             3              2          3              3  ...   \n",
       "\n",
       "     grammar-model-0  grammar-model-1  grammar-model-2  grammar-model-3  \\\n",
       "0           3.945891         3.906997         3.874162         3.937964   \n",
       "1           4.177153         4.026624         4.047930         4.220422   \n",
       "2           4.003042         3.524597         3.769304         3.703856   \n",
       "3           2.944404         3.125247         3.005486         2.804622   \n",
       "4           2.211505         2.137684         2.233499         2.097087   \n",
       "..               ...              ...              ...              ...   \n",
       "968         4.047146         4.007442         4.117114         4.191662   \n",
       "969         3.380976         3.192650         3.298422         3.492209   \n",
       "970         3.586772         3.680668         3.855306         4.028326   \n",
       "971         2.413828         2.485096         2.318097         2.371035   \n",
       "972         3.324507         3.256163         3.232590         3.099558   \n",
       "\n",
       "     grammar-model-4  vocabulary-model-0  vocabulary-model-1  \\\n",
       "0           3.877669            3.740423            3.747329   \n",
       "1           4.240192            3.710368            3.769626   \n",
       "2           3.969286            3.273657            3.245494   \n",
       "3           2.910588            3.406393            3.464580   \n",
       "4           2.239886            2.730236            2.829128   \n",
       "..               ...                 ...                 ...   \n",
       "968         3.901466            4.106008            3.950391   \n",
       "969         3.353168            3.253963            3.284392   \n",
       "970         3.781683            3.617156            3.583234   \n",
       "971         2.304187            2.422342            2.475149   \n",
       "972         3.287645            3.469777            3.537421   \n",
       "\n",
       "     vocabulary-model-2  vocabulary-model-3 vocabulary-model-4  \n",
       "0              3.594682            3.608412           3.749964  \n",
       "1              3.544382            3.738004           3.874523  \n",
       "2              3.113843            3.362435           3.353452  \n",
       "3              3.456613            3.629762           3.518577  \n",
       "4              2.726695            2.693180           2.789509  \n",
       "..                  ...                 ...                ...  \n",
       "968            4.156456            4.176138           4.182713  \n",
       "969            3.280299            3.130947           3.180582  \n",
       "970            3.596291            3.813251           3.465148  \n",
       "971            2.417537            2.380605           2.596770  \n",
       "972            3.303370            3.414260           3.420581  \n",
       "\n",
       "[973 rows x 30 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b603ae8a-59aa-435a-bbff-90534a05a053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../results/cfa.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hf]",
   "language": "python",
   "name": "conda-env-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
