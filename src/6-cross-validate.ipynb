{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1493d6bd-0e19-420a-b63a-83df30f82cc9",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "In this notebook, we will train 2 models using the best hyperparameters for this dataset.\n",
    "\n",
    "We will continue to use the wandb library to track our training runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730a553a-0c6f-4ee3-a63d-b71cdcf4c121",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_ENTITY=langdon\n",
      "env: WANDB_PROJECT=ellipse\n",
      "env: WANDB_DIR=/home/jovyan/active-projects/ellipse-methods-showcase/bin\n"
     ]
    }
   ],
   "source": [
    "# Import Classes for tokenization and model training\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer)\n",
    "\n",
    "# Import DatasetDict which will help us prepare our own dataset for use in training and evaulating machine learning models\n",
    "from datasets import DatasetDict\n",
    "\n",
    "# Import function to be used as loss function\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import library to track our training runs and change settings\n",
    "import wandb\n",
    "\n",
    "# Replace the variables below with your own: name, project name, and project directory\n",
    "%env WANDB_ENTITY = langdon\n",
    "%env WANDB_PROJECT = ellipse\n",
    "%env WANDB_DIR = /home/jovyan/active-projects/ellipse-methods-showcase/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177080b1-2717-4ae0-b856-f72844c625eb",
   "metadata": {},
   "source": [
    "## Load DatasetDict and Tokenize\n",
    "\n",
    "We could have tokenized our datadict when we created the dataset partitions, but waiting until the last minute gives us the flexibility to try out different models that may require different tokenization schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9e764f-e78c-412c-b04a-dd91968dc978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize tokenizer and create helper function for tokenization as we did in the previous notebooks.\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_inputs(example):\n",
    "    return tokenizer(example['text'], max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a87615f-8e33-45a8-b10d-daf0812d4b20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_datadict(score_to_predict):\n",
    "    ''' Selects a target score that the model should predict and renames that score to 'label'.\n",
    "    Removes other columns from the dataset. The other columns are not needed for training.\n",
    "    '''\n",
    "    \n",
    "    # These columns will be removed from the dataset\n",
    "    scores = {\n",
    "        'Overall',\n",
    "        'Cohesion',\n",
    "        'Syntax',\n",
    "        'Vocabulary',\n",
    "        'Phraseology',\n",
    "        'Grammar',\n",
    "        'Conventions'\n",
    "    }\n",
    "    \n",
    "    columns_to_remove = scores.symmetric_difference([score_to_predict])\n",
    "    \n",
    "    # Load the DatasetDict object we created in the previous notebook. \n",
    "    # We will be removing the columns that we defined above, and renaming the target column (=score_to_predict) into 'label'\n",
    "    dd = (DatasetDict\n",
    "          .load_from_disk('../data/ellipse.hf')\n",
    "          .remove_columns(columns_to_remove)\n",
    "          .map(tokenize_inputs, remove_columns=['text_id', 'text']) # the transformer does not need these columns to train.\n",
    "          .rename_column(score_to_predict, 'label') # Huggingface will look for a column that contains the string 'label' to calculate metrics.\n",
    "         )\n",
    "    \n",
    "    return dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3346da08-38c8-440d-a0ef-27759050db9d",
   "metadata": {},
   "source": [
    "## Compute Metric\n",
    "\n",
    "By default, Huggingface will evaluate models based on the sum of metrics produced by this function.\n",
    "\n",
    "We only have one metric (mse), but if other metrics are included (like r-squared), Huggingface needs to know which metric to use (because MSE should be minimized and r-squared should be maximized, summing these values will create a nonsense metric). We will be specifying th metric when we are configuring the training arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b56260e-022b-4655-abdc-8324332ae0c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    mse = mean_squared_error(labels, preds)\n",
    "\n",
    "    return {'mse': mse}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27719516-3918-44b6-b734-b9599b9e4a31",
   "metadata": {},
   "source": [
    "## Train Function\n",
    "\n",
    "We can make some improvements here. The development data is more-or-less wasted with this configuration, so we could either decide not to use it, or we could utilize it by keeping the best model from 4-5 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aef09b1-3ce9-42ff-ad4c-a60ea6ec9266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(score_to_predict):\n",
    "    # load in the dataset we created before with the target column's name changed to 'label'\n",
    "    datadict = get_datadict(score_to_predict)\n",
    "\n",
    "    # Generate in-fold and out-of-fold indexes\n",
    "    folds = ShuffleSplit(n_splits=2, random_state=42)        \n",
    "    splits = folds.split(np.zeros(datadict[\"train\"].num_rows), datadict[\"train\"][\"label\"])\n",
    "    \n",
    "    # Iterate over in-fold and out-of-fold indexes\n",
    "    for i, (inf_idxs, oof_idxs) in enumerate(splits):\n",
    "        # since we create the model from_pretrained() within the train() function, we do not need a model_init()\n",
    "        model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = '../bin/checkpoints',\n",
    "            optim = 'adamw_torch',\n",
    "            logging_dir = f'../logs/{score_to_predict}',\n",
    "            evaluation_strategy='epoch',\n",
    "            save_strategy='no',\n",
    "            log_level='error',\n",
    "            disable_tqdm = False,\n",
    "            report_to='wandb',\n",
    "            num_train_epochs=2, # tuned\n",
    "            learning_rate=5e-5, # tuned\n",
    "            per_device_train_batch_size=16, # tuned\n",
    "            per_device_eval_batch_size=16,\n",
    "        )\n",
    "    \n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=datadict['train'].select(inf_idxs),\n",
    "            eval_dataset=datadict['train'].select(oof_idxs),\n",
    "            compute_metrics=compute_metrics,\n",
    "            tokenizer=tokenizer,\n",
    "        )\n",
    "    \n",
    "        trainer.train()\n",
    "        trainer.save_model(f'../bin/kfold-{score_to_predict.lower()}-models/{score_to_predict.lower()}-model-{i:02}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ca5e4-f0b5-4255-b0e3-70001d125a07",
   "metadata": {},
   "source": [
    "## Train Grammar\n",
    "\n",
    "Finetune a model that predicts the 'Grammar' scores in the ELLIPSE corpus using the function we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "943296c0-bc44-4bec-ab9c-80c7269ff12d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30264107ce54461ca89c116747605291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4537 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364a981ee60b47a09c7e727c8b7afd2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a02b44692e04826a075191a15948b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/973 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlangdon\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/ellipse-methods-showcase/bin/wandb/run-20231013_192935-sglx63n2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/langdon/ellipse/runs/sglx63n2' target=\"_blank\">giddy-valley-67</a></strong> to <a href='https://wandb.ai/langdon/ellipse' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/langdon/ellipse' target=\"_blank\">https://wandb.ai/langdon/ellipse</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/langdon/ellipse/runs/sglx63n2' target=\"_blank\">https://wandb.ai/langdon/ellipse/runs/sglx63n2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='512' max='512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [512/512 03:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.255577</td>\n",
       "      <td>0.255577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.324500</td>\n",
       "      <td>0.265717</td>\n",
       "      <td>0.265717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='512' max='512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [512/512 03:40, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247370</td>\n",
       "      <td>0.247370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.372600</td>\n",
       "      <td>0.250730</td>\n",
       "      <td>0.250730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train('Grammar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed367c-583c-4acd-a0ed-599694e6eb19",
   "metadata": {},
   "source": [
    "## Train Vocabulary\n",
    "\n",
    "We can use the same approach to finetune a model that predicts the 'Vocabulary' scores. We will assume that the optimal hyperparameters are similar for different scores on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "267b472f-34cb-4c26-87a6-648e24e6fa07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37228cae490d4631bc3a3b6e2d73eb18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4537 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b04ebf40ec4e9eb3d73e01c6270bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5421271309ea4de5a4efd3dd493389da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/973 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='512' max='512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [512/512 03:43, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.199172</td>\n",
       "      <td>0.199172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.189354</td>\n",
       "      <td>0.189354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='512' max='512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [512/512 03:43, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.213810</td>\n",
       "      <td>0.213810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.305200</td>\n",
       "      <td>0.191467</td>\n",
       "      <td>0.191467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train('Vocabulary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c31ef-20ad-49d2-b766-365cdd6db40f",
   "metadata": {},
   "source": [
    "# Prepare Dataset for Confirmatory Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77ceeeea-ba8b-4750-bf69-567f012ce842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DatasetDict object we created in the previous notebook. \n",
    "datadict = DatasetDict.load_from_disk('../data/ellipse.hf/')\n",
    "\n",
    "# We are specifically interested in using the test set since we are in our model evaluation phase\n",
    "ds = datadict['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1af32978-fdd7-4ef6-93db-adaa444b4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/both_raters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9e47da2-a192-4fbe-9e89-ff0955f2d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = pd.DataFrame({\n",
    "    \"text_id_original\": ds[\"text_id\"],\n",
    "    \"order\": range(ds.num_rows)\n",
    "})\n",
    "df = pd.merge(idf, df, on=\"text_id_original\").sort_values(\"order\").drop(\"order\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "650dd1c1-4300-429c-b16f-7c5cf7b63fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Model inference pipeline that uses our finetuned model\n",
    "def predict(eval_data, model_path):\n",
    "    pipe = pipeline('text-classification',\n",
    "                    model=model_path,\n",
    "                    truncation=True,\n",
    "                    batch_size=16,\n",
    "                    function_to_apply='none',\n",
    "                   )\n",
    "    \n",
    "    predictions = [pipe(text)[0]['score'] for text in tqdm(eval_data['text'])]\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e053299-ef81-4d1c-b069-cfff22d10cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ad968e6ca54824b2486432c1fa9082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c934c6f0244a42ba227c011c9994e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08945048769408cabad2b393ac6f089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374f15cc2e1449609682e2582b322b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for score_to_predict in [\"grammar\", \"vocabulary\"]:\n",
    "    for i in range(2):\n",
    "        model_path = f\"../bin/kfold-{score_to_predict}-models/{score_to_predict}-model-{i:02}\"\n",
    "        df[f\"{score_to_predict}-model-{i}\"] = predict(ds, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5665aeb3-40f7-40db-a945-5ab1bcf7a5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text_id_original', 'Filename', 'Text', 'Overall_1', 'Cohesion_1',\n",
       "       'Syntax_1', 'Vocabulary_1', 'Phraseology_1', 'Grammar_1',\n",
       "       'Conventions_1', 'Identifying_Info_1', 'Overall_2', 'Cohesion_2',\n",
       "       'Syntax_2', 'Vocabulary_2', 'Phraseology_2', 'Grammar_2',\n",
       "       'Conventions_2', 'Identifying_Info_2', 'text_id_kaggle',\n",
       "       'grammar-model-0', 'grammar-model-1', 'vocabulary-model-0',\n",
       "       'vocabulary-model-1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b603ae8a-59aa-435a-bbff-90534a05a053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../results/cfa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4b09d4-61a6-4fcc-8a76-3663f6d326c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hf]",
   "language": "python",
   "name": "conda-env-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
