{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1493d6bd-0e19-420a-b63a-83df30f82cc9",
   "metadata": {},
   "source": [
    "# Hyperparameter Search\n",
    "\n",
    "In this notebook, we will find the best hyperparameters for our model. The optimal hyperparameters are specific to the dataset and task.\n",
    "\n",
    "We will use two libraries created by HuggingFace: transformers and datasets.\n",
    "\n",
    "We will also use the wandb library to track our training runs and the mean_squared error function from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730a553a-0c6f-4ee3-a63d-b71cdcf4c121",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_ENTITY=langdon\n",
      "env: WANDB_PROJECT=ellipse\n",
      "env: WANDB_DIR=/home/jovyan/active-projects/ellipse-methods-showcase/bin\n"
     ]
    }
   ],
   "source": [
    "# Import classes for tokenization and model training\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer)\n",
    "\n",
    "# Import DatasetDict which will help us prepare our own dataset for use in training and evaulating machine learning models\n",
    "from datasets import DatasetDict\n",
    "\n",
    "# Import function to be used as loss function\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Import library to track our training runs and change settings\n",
    "import wandb\n",
    "\n",
    "# Replace the variables below with your own: name, project name, and project directory\n",
    "%env WANDB_ENTITY = langdon\n",
    "%env WANDB_PROJECT = ellipse\n",
    "%env WANDB_DIR = /home/jovyan/active-projects/ellipse-methods-showcase/bin\n",
    "\n",
    "score_to_predict = 'Grammar'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c80139e-8bf1-483b-ab50-19bdd8f60fd9",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "\n",
    "Hyperparameter optimization can seem intimidating at first, but it is a crucial step of finetuning.\n",
    "\n",
    "Luckily, BERT is a widely used model and its optimal hyperparameters are well understood.\n",
    "\n",
    "The paper that introduced BERT specifies three hyperparameters that should be optimized and their possible values:\n",
    "\n",
    "Batch Size: [16, 32]\n",
    "Batch size determines the number of examples that the transformer processes at once. The minimum value is 1, and the maximum value is limited by the memory of your computer. BERT performs best with a batch size of 16 or 32.\n",
    "\n",
    "Learning Rate: [5e-5, 3e-5, 2e-5]\n",
    "Learning rate determines how quickly the transformer updates its weights during training. A low learning rate will not allow the transformer to learn anything useful. A high learning rate would cause the transformer to \"forget\" the linguistic knowledge it acquired during pretraining. BERT works best with a learning rate of .00005, .00003, or .00002.\n",
    "\n",
    "Epochs: [2, 3, 4]\n",
    "The number of epochs determines how many times the transformer will \"see\" the dataset during training. A value of 1 means that each example is seen only once during training. Too many epochs will cause the transformer to overfit to its training data and perform poorly on validation and test data. BERT works best with 2, 3, or 4 epochs.\n",
    "\n",
    "This means we can do a simple \"grid search\", in which we will test all possible combinations of the above hyperparameters to see what works best on our data. If you are using a free tier of Google Colab, you may need to set the batch size to 16 apriori so Colab does not run out of memory (or consider using a smaller model, like DistilBERT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "115fb9c1-c66d-4584-8c11-87d8f82bd0ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'name': f'{score_to_predict}-optimization',\n",
    "    'method': 'grid',\n",
    "    'metric': {\n",
    "        'name': f'eval/mse',\n",
    "        'goal': 'minimize'}, # we want to \"minimize\" the mean squared error.\n",
    "    'parameters': {\n",
    "        'batch_size': {'values': [16, 32]},\n",
    "        'learning_rate': {'values': [5e-5, 3e-5, 2e-5]},\n",
    "        'epochs': {'values': [2, 3, 4]},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ee6317-61a6-436f-99bf-fae88912fd51",
   "metadata": {},
   "source": [
    "## Create Model Initialization Function\n",
    "\n",
    "We need to start from scratch at the beginning of each trial. To accomplish this, we create a model initialization function.\n",
    "\n",
    "When this function is called by the Trainer, it will instantiate the pre-trained BERT weights with a classification \"head\". \n",
    "\n",
    "The head is a one-layer neural network with randomly initialized weights. This will generate a warning about these weights needing to be trained, which we will do when we finetune the model.\n",
    "\n",
    "`num_labels=1` defines the number of output nodes that the classification head should have. We want one output node corresopnding to the numeric value of the score. This is also called a 'regression' task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95abbef8-c509-4579-9bf9-5d4a25b15827",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_init(trial):\n",
    "    return AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27719516-3918-44b6-b734-b9599b9e4a31",
   "metadata": {},
   "source": [
    "## Load Model and Tokenizer\n",
    "The pretrained BERT weights come in many flavors. We will use 'bert-base-uncased' because it is the most widely used version. It has fewer parameters than many newer transformer models, making it easier to work with.\n",
    "\n",
    "This creates the tokenizer. It is critical that we tokenize our data using the same tokenizer that was used during language model pre-training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b228df9d-aeb0-4d41-948c-357b3f3678fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9848492a9c334b7d86f3d686ead37f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36719e2b08c2444e96ed34bf5f835725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d6c4caab10493ab6b19772735ad026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0587edc624e416f9594e3e6a65421eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c1d9f8-0b4e-485b-9249-d8cfff755835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create function that will take a text as an input, tokenize it, and return numeric representations for each individual token.\n",
    "# We will be setting the truncation parameter to True this time.\n",
    "def tokenize_inputs(example):\n",
    "    return tokenizer(example['text'], max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177080b1-2717-4ae0-b856-f72844c625eb",
   "metadata": {},
   "source": [
    "## Load DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a87615f-8e33-45a8-b10d-daf0812d4b20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text_id', 'text', 'label'],\n",
       "        num_rows: 4537\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['text_id', 'text', 'label'],\n",
       "        num_rows: 972\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text_id', 'text', 'label'],\n",
       "        num_rows: 973\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_datadict(score_to_predict):\n",
    "    ''' Selects a target score that the model should predict and renames that score to 'label'.\n",
    "    Removes other columns from the dataset. The other columns are not needed for training.\n",
    "    '''\n",
    "    \n",
    "    # These columns will be removed from the dataset\n",
    "    scores = {\n",
    "        'Overall',\n",
    "        'Cohesion',\n",
    "        'Syntax',\n",
    "        'Vocabulary',\n",
    "        'Phraseology',\n",
    "        'Grammar',\n",
    "        'Conventions'\n",
    "    }\n",
    "    \n",
    "    columns_to_remove = scores.symmetric_difference([score_to_predict])\n",
    "    \n",
    "    # Load the DatasetDict object we created in the previous notebook. \n",
    "    # We will be removing the columns that we defined above, and renaming the target column (=score_to_predict) into 'label'\n",
    "    dd = (DatasetDict\n",
    "          .load_from_disk('../data/ellipse.hf')\n",
    "          .remove_columns(columns_to_remove)\n",
    "          .rename_column(score_to_predict, 'label') # Huggingface will look for a column that contains the string 'label' to calculate metrics.\n",
    "         )\n",
    "    \n",
    "    return dd\n",
    "\n",
    "# Load dataset using the function\n",
    "datadict = get_datadict(score_to_predict)\n",
    "datadict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0214035d-5016-4696-baf6-0f3eec9487c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Would you like to start your life early?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the first 40 characters of the first text in the training set\n",
    "datadict['train'][0]['text'][:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee894ec-09ee-4220-ad3b-69aefb10b43b",
   "metadata": {},
   "source": [
    "### Tokenize the texts\n",
    "\n",
    "Transformers do not understand text, they process language as sequences of numbers. We have created the \"tokenize_inputs\" function above to help us with this step.\n",
    "\n",
    "Our DatasetDict has a map function that we can use to apply this function to the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a59ae271-6f7f-46a6-9306-3b2c4b1a267b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ebf5f1f7eba44ff870bb0fd0f2a52d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4537 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b056b6b6289447f68d49953bb4f9356d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33f98bab43343ddb19e26918972225d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/973 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 4537\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 972\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 973\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadict = datadict.map(tokenize_inputs, remove_columns=['text_id', 'text'])\n",
    "datadict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f162de29-bd96-4b7e-884e-0a7ecf90dff4",
   "metadata": {},
   "source": [
    "### Input IDs\n",
    "\n",
    "The tokenizer breaks down a text into pieces of words that are in the model's vocabulary and maps them to unique ids. For example, the tokenizer breaks down the proper noun HuggingFace into 'hugging' and '##face' and maps them to their corresponding ids (17662 and 12172). The sequence ids for the tokens are what we feed to the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4b0ffd7-fb9b-4aa9-b39b-9159473fff6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2052, 2017, 2066, 2000, 2707, 2115, 2166, 2220, 1029]\n"
     ]
    }
   ],
   "source": [
    "# These are the ids for the first ten tokens for the first text in the training set.\n",
    "# This is incomprehensible to humans but it makes perfect sense to BERT\n",
    "print(datadict['train'][0]['input_ids'][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b52fe6-7a62-42df-9d07-f7782e05bdd1",
   "metadata": {},
   "source": [
    "If we want, we can convert these IDs back to text. We are using the \"uncased\" version of BERT, so capitalization is lost.\n",
    "\n",
    "Notice that the tokenizer added a special \"[CLS]\" token. This is the *classification* token, and it is meant to develop a representation of the whole document. \n",
    "\n",
    "The classification head that we train only looks at the CLS token embedding, but we backpropagate on the whole model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "633a0aeb-c87c-4772-bc38-34872fe1df82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] would you like to start your life early?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the ids back to human-readable form.\n",
    "tokenizer.decode(datadict['train'][0]['input_ids'][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0e902e-e66f-4394-bb21-eb9b1dcea6ee",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance\n",
    "\n",
    "In order to choose the best hyperparameters, we need to know which model performs best. Mean squared error is the default loss function that the transformer learns to minimize during training. We can also use this for evaluation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b56260e-022b-4655-abdc-8324332ae0c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a function that will help us evaluate the model's performance by calculating the mean squared error of the model's predictions\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    mse = mean_squared_error(labels, preds)\n",
    "\n",
    "    return {'mse': mse}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f59b1a-a27f-4fbc-930d-e738454e433c",
   "metadata": {},
   "source": [
    "## Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05f9f252-8ccb-400d-a8a1-006416acf46c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is the function we will be using for HP optimization\n",
    "def train():\n",
    "    with wandb.init():\n",
    "        # set sweep configuration\n",
    "        config = wandb.config\n",
    "\n",
    "        # Customize the trainer\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = '../bin', \n",
    "            optim = 'adamw_torch', # Specify your optimizer\n",
    "            logging_dir = f'../logs/{score_to_predict}', \n",
    "            load_best_model_at_end = False,\n",
    "            metric_for_best_model = 'mse', # We will be using mean squared error to evaluate model performance\n",
    "            evaluation_strategy='epoch', # Evaluate model performance at the end of each epoch\n",
    "            save_strategy='no', # I prefer to perform a training run separately once the best parameters are discovered.\n",
    "            greater_is_better = False,\n",
    "            log_level = 'error',\n",
    "            disable_tqdm = False,\n",
    "            report_to='wandb',\n",
    "            # The hyper parameters we are tuning (umber of epochs, learning rate, and batch size) are called in from the configuration dictionary\n",
    "            num_train_epochs=config.epochs, \n",
    "            learning_rate=config.learning_rate,\n",
    "            per_device_train_batch_size=config.batch_size,\n",
    "            per_device_eval_batch_size=16,\n",
    "        )\n",
    "\n",
    "        # Initialize the trainer\n",
    "        trainer = Trainer(\n",
    "            model=None, # this is to emphasize that we are not passing the model directly\n",
    "            args=training_args,\n",
    "            train_dataset=datadict['train'],\n",
    "            eval_dataset=datadict['dev'],\n",
    "            compute_metrics=compute_metrics,\n",
    "            tokenizer=tokenizer,\n",
    "            model_init=model_init, # we pass a function that initializes the model afresh at the start of each trial\n",
    "        )\n",
    "\n",
    "\n",
    "        # Start training loop\n",
    "        trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da68bb06-71dd-40a8-87ac-68026b250fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\n"
     ]
    },
    {
     "ename": "Abort",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAbort\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Start HP tuning. This will take a long time since we will be finetuning multiple models and comparing their performances.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sweep_id \u001b[38;5;241m=\u001b[39m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msweep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msweep_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#wandb.agent(sweep_id, train)\u001b[39;00m\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/wandb/sdk/wandb_sweep.py:108\u001b[0m, in \u001b[0;36msweep\u001b[0;34m(sweep, entity, project)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Make sure we are logged in\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mrun \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m     \u001b[43mwandb_login\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_login\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_silent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m api \u001b[38;5;241m=\u001b[39m InternalApi()\n\u001b[1;32m    110\u001b[0m sweep_id, warnings \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mupsert_sweep(sweep)\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/wandb/sdk/wandb_login.py:298\u001b[0m, in \u001b[0;36m_login\u001b[0;34m(anonymous, key, relogin, host, force, timeout, _backend, _silent, _disable_warning, _entity)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logged_in\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m key:\n\u001b[0;32m--> 298\u001b[0m     \u001b[43mwlogin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# make sure login credentials get to the backend\u001b[39;00m\n\u001b[1;32m    301\u001b[0m wlogin\u001b[38;5;241m.\u001b[39mpropogate_login()\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/wandb/sdk/wandb_login.py:221\u001b[0m, in \u001b[0;36m_WandbLogin.prompt_api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprompt_api_key\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 221\u001b[0m     key, status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prompt_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m ApiKeyStatus\u001b[38;5;241m.\u001b[39mNOTTY:\n\u001b[1;32m    223\u001b[0m         directive \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwandb login [your_api_key]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings\u001b[38;5;241m.\u001b[39m_cli_only_mode\n\u001b[1;32m    226\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwandb.login(key=[your_api_key])\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    227\u001b[0m         )\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/wandb/sdk/wandb_login.py:201\u001b[0m, in \u001b[0;36m_WandbLogin._prompt_api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[43mapikey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_api_key\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m            \u001b[49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m            \u001b[49m\u001b[43mno_offline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m            \u001b[49m\u001b[43mno_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;66;03m# invalid key provided, try again\u001b[39;00m\n\u001b[1;32m    209\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mtermerror(e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/wandb/sdk/lib/apikey.py:144\u001b[0m, in \u001b[0;36mprompt_api_key\u001b[0;34m(settings, api, input_callback, browser_callback, no_offline, no_create, local)\u001b[0m\n\u001b[1;32m    138\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mtermlog(\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogging into \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. (Learn how to deploy a W&B server locally: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwburls\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwandb_server\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         )\n\u001b[1;32m    141\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mtermlog(\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can find your API key in your browser here: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapp_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/authorize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m     )\n\u001b[0;32m--> 144\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43minput_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_ask\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m    145\u001b[0m write_key(settings, key, api\u001b[38;5;241m=\u001b[39mapi)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m key  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/click/termui.py:164\u001b[0m, in \u001b[0;36mprompt\u001b[0;34m(text, default, hide_input, confirmation_prompt, type, value_proc, prompt_suffix, show_default, err, show_choices)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value:\n\u001b[1;32m    166\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/click/termui.py:147\u001b[0m, in \u001b[0;36mprompt.<locals>.prompt_func\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hide_input:\n\u001b[1;32m    146\u001b[0m     echo(\u001b[38;5;28;01mNone\u001b[39;00m, err\u001b[38;5;241m=\u001b[39merr)\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Abort() \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAbort\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start HP tuning. This will take a long time since we will be finetuning multiple models and comparing their performances.\n",
    "sweep_id = wandb.sweep(sweep_config)\n",
    "wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c120ae70-a44c-4b8a-b16f-f729cde6a13f",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The best trial is the one that has the lowest mean squared error on the development set. The optimal hyperparameters are epochs = 2, batch_size = 16, and learning rate = 5e-5. This results in a mean squared error of 0.246 on the development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d85e57-7f13-401a-9612-0eac8107e36e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wes_main]",
   "language": "python",
   "name": "conda-env-wes_main-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
