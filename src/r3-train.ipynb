{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1493d6bd-0e19-420a-b63a-83df30f82cc9",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "In this notebook, we will train a collection of models using the same hyperparameter config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730a553a-0c6f-4ee3-a63d-b71cdcf4c121",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_ENTITY=langdon\n",
      "env: WANDB_PROJECT=ellipse\n",
      "env: WANDB_DIR=/home/jovyan/active-projects/ellipse-methods-showcase/bin\n"
     ]
    }
   ],
   "source": [
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer, logging)\n",
    "\n",
    "from datasets import DatasetDict, Value\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import wandb\n",
    "\n",
    "%env WANDB_ENTITY = langdon\n",
    "%env WANDB_PROJECT = ellipse\n",
    "%env WANDB_DIR = /home/jovyan/active-projects/ellipse-methods-showcase/bin\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "model_name='microsoft/deberta-v3-large'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177080b1-2717-4ae0-b856-f72844c625eb",
   "metadata": {},
   "source": [
    "## Load DatasetDict and Tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9e764f-e78c-412c-b04a-dd91968dc978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize tokenizer and create helper function for tokenization as we did in the previous notebooks.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "\n",
    "# We do our final training runs without truncating the texts\n",
    "# This is substantially more computationally expensive, but it may (slightly) improve model performance\n",
    "# Not all model architectures can process longer documents. DeBERTa can do it at a steep cost.\n",
    "def tokenize_inputs(example):\n",
    "    return tokenizer(example['text'], truncation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a87615f-8e33-45a8-b10d-daf0812d4b20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_datadict():\n",
    "    ''' Selects a target score that the model should predict and renames that score to 'label'.\n",
    "    Removes other columns from the dataset. The other columns are not needed for training.\n",
    "    '''\n",
    "    \n",
    "    # Load the DatasetDict object we created in the previous notebook. \n",
    "    # We will be removing the columns that we defined above, and renaming the target column (=score_to_predict) into 'label'\n",
    "    dd = (DatasetDict\n",
    "          .load_from_disk('../data/raw_ellipse.hf')\n",
    "          .map(tokenize_inputs, remove_columns=['text']) # the transformer does not need these columns to train.\n",
    "         )\n",
    "    \n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92623206-92f9-40a4-af5e-4fa392ea2971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe56a5c889d4974a5f25f7148ce94a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6216 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ae4f547f04418890fea7c05526607b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4e14ec5e79487ea4816329ed4903c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datadict = get_datadict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b56260e-022b-4655-abdc-8324332ae0c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    mse = mean_squared_error(labels, preds)\n",
    "\n",
    "    return {'mse': mse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be617e6d-49be-48bc-ae1d-22e131828edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'overall_1', 'cohesion_1', 'syntax_1', 'vocabulary_1', 'phraseology_1', 'grammar_1', 'conventions_1', 'overall_2', 'cohesion_2', 'syntax_2', 'vocabulary_2', 'phraseology_2', 'grammar_2', 'conventions_2', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 6216\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['id', 'overall_1', 'cohesion_1', 'syntax_1', 'vocabulary_1', 'phraseology_1', 'grammar_1', 'conventions_1', 'overall_2', 'cohesion_2', 'syntax_2', 'vocabulary_2', 'phraseology_2', 'grammar_2', 'conventions_2', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1332\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'overall_1', 'cohesion_1', 'syntax_1', 'vocabulary_1', 'phraseology_1', 'grammar_1', 'conventions_1', 'overall_2', 'cohesion_2', 'syntax_2', 'vocabulary_2', 'phraseology_2', 'grammar_2', 'conventions_2', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1332\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27719516-3918-44b6-b734-b9599b9e4a31",
   "metadata": {},
   "source": [
    "## Train Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c3324b4-5ee3-4cce-901c-4dd216702e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size': 2,\n",
    "    'gradient_accumulation_steps': 16,\n",
    "    'learning_rate': 1e-5,\n",
    "    'num_train_epochs': 2,\n",
    "    'pooler_dropout': 0.30,\n",
    "    'weight_decay': 0.01,\n",
    "    'adam_beta1': 0.900,\n",
    "    'adam_beta2': 0.999,\n",
    "    'adam_epsilon': 1e-6, \n",
    "    'warmup_steps': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3666c36-3f9f-41be-b3f7-c94b08138587",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_to_predict = [\n",
    "    'overall_1', #'cohesion_1', 'syntax_1', 'vocabulary_1', 'phraseology_1', 'grammar_1', 'conventions_1',\n",
    "    'overall_2', #'cohesion_2', 'syntax_2', 'vocabulary_2', 'phraseology_2', 'grammar_2', 'conventions_2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aef09b1-3ce9-42ff-ad4c-a60ea6ec9266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(score_to_predict):\n",
    "\n",
    "    print(score_to_predict)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, num_labels=1, pooler_dropout=config['pooler_dropout']\n",
    "    )\n",
    "\n",
    "    ignored_columns = list(set(scores_to_predict) - {score_to_predict}) + ['id']\n",
    "    \n",
    "    _dd = (\n",
    "        datadict\n",
    "        .remove_columns(ignored_columns)\n",
    "        .rename_column(score_to_predict, 'label')\n",
    "        .cast_column('label', Value(\"float32\"))\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        optim = 'adamw_torch',\n",
    "        output_dir=f'..bin/{model_name}',\n",
    "        logging_dir = f'../logs/{score_to_predict}',\n",
    "        load_best_model_at_end = False,\n",
    "        evaluation_strategy='no',\n",
    "        save_strategy='no',\n",
    "        greater_is_better = False,\n",
    "        log_level = 'error',\n",
    "        disable_tqdm = False,\n",
    "        run_name=f'deberta-v3-large-no-trunc{score_to_predict}',\n",
    "        report_to='wandb',\n",
    "        adam_beta1=config['adam_beta1'],\n",
    "        adam_beta2=config['adam_beta2'],\n",
    "        adam_epsilon=config['adam_epsilon'],\n",
    "        num_train_epochs=config['num_train_epochs'],\n",
    "        warmup_steps=config['warmup_steps'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        per_device_train_batch_size=config['batch_size'],\n",
    "        per_device_eval_batch_size=16,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=_dd['train'],\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    predictions = trainer.predict(test_dataset=_dd['test']).predictions\n",
    "\n",
    "    results = pd.DataFrame({f'deberta_{score_to_predict}': predictions})\n",
    "    results = results.set_index(pd.Index(datadict['test']['id']))\n",
    "    results.to_csv(f'../results/deberta-v3-large-no-trunc/{score_to_predict}.csv')\n",
    "\n",
    "    trainer.save_model(output_dir=f'../bin/deberta-v3-large-models-no-trunc/{score_to_predict}')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ca5e4-f0b5-4255-b0e3-70001d125a07",
   "metadata": {},
   "source": [
    "## Train Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b472f-34cb-4c26-87a6-648e24e6fa07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77143ede0da94ffea465a02257dab8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/6216 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0789c301de4245a49ac77d1db2e2589d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28228f8848a648cd944f7ba3aeba48c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlangdon\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/ellipse-methods-showcase/bin/wandb/run-20240313_231539-xw505k1p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/langdon/ellipse/runs/xw505k1p' target=\"_blank\">deberta-v3-large-no-truncoverall_1</a></strong> to <a href='https://wandb.ai/langdon/ellipse' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/langdon/ellipse' target=\"_blank\">https://wandb.ai/langdon/ellipse</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/langdon/ellipse/runs/xw505k1p' target=\"_blank\">https://wandb.ai/langdon/ellipse/runs/xw505k1p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2733' max='6216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2733/6216 17:55 < 22:51, 2.54 it/s, Epoch 0.88/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.788800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.466100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.377200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.392300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.392400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for score_to_predict in scores_to_predict:\n",
    "    train(score_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc220dc-ffda-4361-a68d-5fc532cdde9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hf]",
   "language": "python",
   "name": "conda-env-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
