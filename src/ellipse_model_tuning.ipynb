{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b3e5f79-1d11-4380-a26f-656a13ff66be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# !pip install 'ray[tune]'\n",
    "# !pip install wandb\n",
    "# !wandb login\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77319b97-1f02-40dc-9ba8-22983531643b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>gender</th>\n",
       "      <th>grade</th>\n",
       "      <th>race_ethnicity</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_words2</th>\n",
       "      <th>num_words3</th>\n",
       "      <th>num_sent</th>\n",
       "      <th>num_para</th>\n",
       "      <th>...</th>\n",
       "      <th>task</th>\n",
       "      <th>SES</th>\n",
       "      <th>prompt</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Cohesion</th>\n",
       "      <th>Syntax</th>\n",
       "      <th>Vocabulary</th>\n",
       "      <th>Phraseology</th>\n",
       "      <th>Grammar</th>\n",
       "      <th>Conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021000501</td>\n",
       "      <td>Dear, TEACHER_NAME\\n\\nI think phone policy at ...</td>\n",
       "      <td>Male</td>\n",
       "      <td>8</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>111</td>\n",
       "      <td>122</td>\n",
       "      <td>118</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Economically disadvantaged</td>\n",
       "      <td>Cell phones at school</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021000535</td>\n",
       "      <td>Dear, Principal\\r\\n\\r\\nIn my opinion, I think ...</td>\n",
       "      <td>Female</td>\n",
       "      <td>8</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>99</td>\n",
       "      <td>105</td>\n",
       "      <td>102</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Economically disadvantaged</td>\n",
       "      <td>Cell phones at school</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021000667</td>\n",
       "      <td>PHONES\\n\\nDear principal students should have ...</td>\n",
       "      <td>Female</td>\n",
       "      <td>8</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>121</td>\n",
       "      <td>134</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Economically disadvantaged</td>\n",
       "      <td>Cell phones at school</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021000683</td>\n",
       "      <td>phones\\n\\ni think phones should be allowed in ...</td>\n",
       "      <td>Male</td>\n",
       "      <td>8</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>182</td>\n",
       "      <td>202</td>\n",
       "      <td>192</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Economically disadvantaged</td>\n",
       "      <td>Cell phones at school</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021000705</td>\n",
       "      <td>Do you really think students need cell phones ...</td>\n",
       "      <td>Female</td>\n",
       "      <td>8</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>192</td>\n",
       "      <td>210</td>\n",
       "      <td>201</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Not economically disadvantaged</td>\n",
       "      <td>Cell phones at school</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477</th>\n",
       "      <td>AAAXMP138200002211022133_OR</td>\n",
       "      <td>The decision regarding extracurricular involve...</td>\n",
       "      <td>Male</td>\n",
       "      <td>12</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>348</td>\n",
       "      <td>369</td>\n",
       "      <td>368</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Economically disadvantaged</td>\n",
       "      <td>Controlling extracurricular involvement</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6478</th>\n",
       "      <td>AAAXMP138200002211062115_OR</td>\n",
       "      <td>The school plans to change to a new, healthier...</td>\n",
       "      <td>Male</td>\n",
       "      <td>12</td>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>423</td>\n",
       "      <td>470</td>\n",
       "      <td>458</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Economically disadvantaged</td>\n",
       "      <td>Lunch menus</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6479</th>\n",
       "      <td>AAAXMP138200002211752151_OR</td>\n",
       "      <td>I raised by my grandparents and they always to...</td>\n",
       "      <td>Female</td>\n",
       "      <td>12</td>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>482</td>\n",
       "      <td>520</td>\n",
       "      <td>510</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Not economically disadvantaged</td>\n",
       "      <td>Curfews for teenagers</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6480</th>\n",
       "      <td>AAAXMP138200002214212144_OR</td>\n",
       "      <td>Imagine the world if students didn't complete ...</td>\n",
       "      <td>Female</td>\n",
       "      <td>12</td>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>758</td>\n",
       "      <td>860</td>\n",
       "      <td>835</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Economically disadvantaged</td>\n",
       "      <td>Summer projects</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6481</th>\n",
       "      <td>AAAXMP138200002216072138_OR</td>\n",
       "      <td>Most employers are looking for specific charac...</td>\n",
       "      <td>Female</td>\n",
       "      <td>11</td>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>271</td>\n",
       "      <td>279</td>\n",
       "      <td>278</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Not economically disadvantaged</td>\n",
       "      <td>Controlling extracurricular involvement</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6482 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          text_id  \\\n",
       "0                      2021000501   \n",
       "1                      2021000535   \n",
       "2                      2021000667   \n",
       "3                      2021000683   \n",
       "4                      2021000705   \n",
       "...                           ...   \n",
       "6477  AAAXMP138200002211022133_OR   \n",
       "6478  AAAXMP138200002211062115_OR   \n",
       "6479  AAAXMP138200002211752151_OR   \n",
       "6480  AAAXMP138200002214212144_OR   \n",
       "6481  AAAXMP138200002216072138_OR   \n",
       "\n",
       "                                              full_text  gender  grade  \\\n",
       "0     Dear, TEACHER_NAME\\n\\nI think phone policy at ...    Male      8   \n",
       "1     Dear, Principal\\r\\n\\r\\nIn my opinion, I think ...  Female      8   \n",
       "2     PHONES\\n\\nDear principal students should have ...  Female      8   \n",
       "3     phones\\n\\ni think phones should be allowed in ...    Male      8   \n",
       "4     Do you really think students need cell phones ...  Female      8   \n",
       "...                                                 ...     ...    ...   \n",
       "6477  The decision regarding extracurricular involve...    Male     12   \n",
       "6478  The school plans to change to a new, healthier...    Male     12   \n",
       "6479  I raised by my grandparents and they always to...  Female     12   \n",
       "6480  Imagine the world if students didn't complete ...  Female     12   \n",
       "6481  Most employers are looking for specific charac...  Female     11   \n",
       "\n",
       "              race_ethnicity  num_words  num_words2  num_words3  num_sent  \\\n",
       "0            Hispanic/Latino        111         122         118         7   \n",
       "1            Hispanic/Latino         99         105         102         6   \n",
       "2            Hispanic/Latino        121         134         128         4   \n",
       "3            Hispanic/Latino        182         202         192         2   \n",
       "4            Hispanic/Latino        192         210         201        11   \n",
       "...                      ...        ...         ...         ...       ...   \n",
       "6477         Hispanic/Latino        348         369         368        17   \n",
       "6478  Asian/Pacific Islander        423         470         458        15   \n",
       "6479  Asian/Pacific Islander        482         520         510        28   \n",
       "6480  Asian/Pacific Islander        758         860         835        50   \n",
       "6481  Asian/Pacific Islander        271         279         278        25   \n",
       "\n",
       "      num_para  ...         task                             SES  \\\n",
       "0            2  ...  Independent      Economically disadvantaged   \n",
       "1            2  ...  Independent      Economically disadvantaged   \n",
       "2            2  ...  Independent      Economically disadvantaged   \n",
       "3            2  ...  Independent      Economically disadvantaged   \n",
       "4            4  ...  Independent  Not economically disadvantaged   \n",
       "...        ...  ...          ...                             ...   \n",
       "6477         5  ...  Independent      Economically disadvantaged   \n",
       "6478         7  ...  Independent      Economically disadvantaged   \n",
       "6479         5  ...  Independent  Not economically disadvantaged   \n",
       "6480         6  ...  Independent      Economically disadvantaged   \n",
       "6481         4  ...  Independent  Not economically disadvantaged   \n",
       "\n",
       "                                       prompt  Overall  Cohesion Syntax  \\\n",
       "0                       Cell phones at school      3.0       3.5    2.5   \n",
       "1                       Cell phones at school      3.0       2.5    3.0   \n",
       "2                       Cell phones at school      3.0       2.5    3.0   \n",
       "3                       Cell phones at school      3.0       2.0    2.5   \n",
       "4                       Cell phones at school      3.0       2.0    3.0   \n",
       "...                                       ...      ...       ...    ...   \n",
       "6477  Controlling extracurricular involvement      4.0       4.0    4.0   \n",
       "6478                              Lunch menus      3.5       3.5    3.0   \n",
       "6479                    Curfews for teenagers      4.0       4.0    3.0   \n",
       "6480                          Summer projects      3.5       3.5    3.5   \n",
       "6481  Controlling extracurricular involvement      2.5       3.0    2.5   \n",
       "\n",
       "     Vocabulary Phraseology  Grammar  Conventions  \n",
       "0           3.5         3.0      3.5          2.5  \n",
       "1           4.0         3.5      3.0          3.5  \n",
       "2           3.0         3.0      3.5          3.0  \n",
       "3           3.0         3.0      3.0          2.5  \n",
       "4           3.0         3.0      3.0          2.0  \n",
       "...         ...         ...      ...          ...  \n",
       "6477        3.5         4.0      4.0          4.5  \n",
       "6478        3.5         3.0      3.5          3.5  \n",
       "6479        4.0         4.0      3.0          4.0  \n",
       "6480        4.0         4.0      3.0          3.0  \n",
       "6481        3.0         2.5      2.5          2.0  \n",
       "\n",
       "[6482 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ellipse_df = pd.read_csv(\"../data/ELLIPSE_Full_manual_clean_finished_calculated.csv\")\n",
    "\n",
    "ellipse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cc2b2f3-f4f2-410c-8bed-95f27c0084a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1899/2687344967.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(lambda x: x.strip())\n"
     ]
    }
   ],
   "source": [
    "df = ellipse_df[['full_text', 'Overall']]\n",
    "df.columns = ['text', 'labels']\n",
    "df['text'] = df['text'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d7b13-67ea-4f54-a447-efe240fd5ab9",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14f6e7d9-0dc6-4abe-a4cf-cb5e47894f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric, Dataset, Value, ClassLabel, Features, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c0691de-e66c-4ade-a59b-68628ea26264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDataset(df):\n",
    "    full_dataset = Dataset.from_pandas(df, preserve_index=False)\n",
    "    # 70% train, 30% test\n",
    "    train_test = full_dataset.train_test_split(test_size=0.3, seed=seed)\n",
    "    test_valid = train_test['test'].train_test_split(test_size=0.5, seed=seed)\n",
    "    # gather everyone if you want to have a single DatasetDict\n",
    "    final_dataset = DatasetDict({\n",
    "        'train': train_test['train'],\n",
    "        'valid': test_valid['test'], \n",
    "        'test': test_valid['test']})\n",
    "    return final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd3ae858-0558-4eae-a185-2290dc51e1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 4537\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 973\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 973\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = buildDataset(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f68c79b2-3c81-4203-85cd-7542df762dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from transformers import LongformerTokenizer, LongformerForSequenceClassification, LongformerConfig\n",
    "\n",
    "import torch\n",
    "model_name =  'allenai/longformer-base-4096'\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc9e2f86-b511-4955-929b-4242a93144f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6523c4b1b6d549b1bfff1a708e233be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef8686efa184be59b3b54618b0afc33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8fb0cfb45244b483f2eb8525440886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = LongformerTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_inputs(example):\n",
    "    return tokenizer(example['text'], max_length=2048, truncation=True)\n",
    "\n",
    "ds_t = ds.map(tokenize_inputs, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f81f3756-2ad0-46d9-9fe9-ed03948da315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr \n",
    "\n",
    "def compute_metrics_for_regression(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    mse = mean_squared_error(labels, logits)\n",
    "    rmse = mean_squared_error(labels, logits, squared=False)\n",
    "    mae = mean_absolute_error(labels, logits)\n",
    "    r2 = r2_score(labels, logits)\n",
    "    smape = 1/len(labels) * np.sum(2 * np.abs(logits-labels) / (np.abs(labels) + np.abs(logits))*100)\n",
    "\n",
    "    return {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"r2\": r2, \"smape\": smape}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86e03a94-0538-4f61-ae3e-3a864829bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-05\n",
    "batch_size = 16\n",
    "seed = 42\n",
    "num_epochs = 4\n",
    "\n",
    "def model_init():\n",
    "    return LongformerForSequenceClassification.from_pretrained(model_name, num_labels=1).to(device)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "24a2126e-83fb-46b5-a088-ab8518b3cfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='284' max='284' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [284/284 1:02:27, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "      <th>Mae</th>\n",
       "      <th>R2</th>\n",
       "      <th>Smape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.177413</td>\n",
       "      <td>0.177413</td>\n",
       "      <td>0.421204</td>\n",
       "      <td>0.331478</td>\n",
       "      <td>0.584401</td>\n",
       "      <td>21946.404933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.311452</td>\n",
       "      <td>0.311452</td>\n",
       "      <td>0.558079</td>\n",
       "      <td>0.453695</td>\n",
       "      <td>0.270408</td>\n",
       "      <td>23740.604317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.285941</td>\n",
       "      <td>0.285941</td>\n",
       "      <td>0.534734</td>\n",
       "      <td>0.430075</td>\n",
       "      <td>0.330170</td>\n",
       "      <td>23622.526208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266363</td>\n",
       "      <td>0.266363</td>\n",
       "      <td>0.516104</td>\n",
       "      <td>0.413384</td>\n",
       "      <td>0.376031</td>\n",
       "      <td>23046.271326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=284, training_loss=0.5531680147412797, metrics={'train_runtime': 3758.0035, 'train_samples_per_second': 4.829, 'train_steps_per_second': 0.076, 'total_flos': 1.1167196968195386e+16, 'train_loss': 0.5531680147412797, 'epoch': 4.0})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer = Trainer(\n",
    "#     model_init=model_init,\n",
    "# )\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = 'test',\n",
    "    optim = 'adamw_torch',\n",
    "    num_train_epochs = num_epochs,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    gradient_accumulation_steps=4, \n",
    "    gradient_checkpointing=True,\n",
    "    weight_decay = 0.01,\n",
    "    learning_rate = learning_rate,\n",
    "    logging_dir = f'./logs/content',\n",
    "    save_total_limit = 10,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = 'mse',\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\", \n",
    "    greater_is_better = False,\n",
    "    seed=seed,\n",
    "    log_level = 'error',  # took me ages to find these options\n",
    "    disable_tqdm = False, # enable output cell scrolling in JupyterLab for even more beautiful output :D\n",
    ") \n",
    "\n",
    "    # Call the Trainer\n",
    "trainer = Trainer(\n",
    "    model_init = model_init,\n",
    "    args = training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset = ds_t['train'],\n",
    "    eval_dataset = ds_t['valid'],\n",
    "    compute_metrics = compute_metrics_for_regression,\n",
    "    #callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2121ff6-8b2e-43b2-99d0-cd6fa5816314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./test/checkpoint-6810 were not used when initializing LongformerForSequenceClassification: ['longformer.embeddings.position_ids']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LongformerForSequenceClassification' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m LongformerForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./test/checkpoint-6810\u001b[39m\u001b[38;5;124m'\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m preds, labs, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(ds_t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(scipy\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mpearsonr(labs, preds))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n",
      "File \u001b[0;32m~/conda_envs/wesEnv/lib/python3.10/site-packages/torch/nn/modules/module.py:1265\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1265\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LongformerForSequenceClassification' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "model = LongformerForSequenceClassification.from_pretrained('./test/checkpoint-6810', num_labels=1)\n",
    "\n",
    "import scipy\n",
    "preds, labs, metrics = model.predict(ds_t['test'])\n",
    "print(scipy.stats.pearsonr(labs, preds))\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "preds.flatten()\n",
    "plt.scatter(preds, actual, alpha=0.5)\n",
    "plt.ylabel('true score')\n",
    "plt.xlabel('predicted score')\n",
    "plt.title('Model Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff4c8a3-da4e-4a08-bd09-ababbc6cffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return LongformerForSequenceClassification.from_pretrained(model_name, num_labels=1, return_dict=True).to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"test\", \n",
    "    evaluation_strategy=\"epoch\", \n",
    "    disable_tqdm=True,\n",
    "    gradient_accumulation_steps=4, \n",
    "    gradient_checkpointing=True,\n",
    "    report_to=\"wandb\",)\n",
    "\n",
    "trainer = Trainer(\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=ds_t[\"train\"],\n",
    "    eval_dataset=ds_t[\"valid\"],\n",
    "    model_init=model_init,\n",
    "    compute_metrics=compute_metrics_for_regression,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),    \n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.hyperparameter_search(\n",
    "    direction=\"minimize\", \n",
    "    backend=\"ray\", \n",
    "    n_trials=10, # number of trials\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489d92e1-1745-472e-8422-bb575bd11046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0facc63-a316-466b-9592-0e49651196c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wesEnv]",
   "language": "python",
   "name": "conda-env-wesEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
