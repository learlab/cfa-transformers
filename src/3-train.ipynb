{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1493d6bd-0e19-420a-b63a-83df30f82cc9",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "In this notebook, we will train 2 models using the best hyperparameters for this dataset.\n",
    "\n",
    "We will continue to use the wandb library to track our training runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "730a553a-0c6f-4ee3-a63d-b71cdcf4c121",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_ENTITY=langdon\n",
      "env: WANDB_PROJECT=ellipse\n",
      "env: WANDB_DIR=/home/jovyan/active-projects/ellipse-methods-showcase/bin\n"
     ]
    }
   ],
   "source": [
    "# Import Classes for tokenization and model training\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer)\n",
    "\n",
    "# Import DatasetDict which will help us prepare our own dataset for use in training and evaulating machine learning models\n",
    "from datasets import DatasetDict\n",
    "\n",
    "# Import function to be used as loss function\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Import library to track our training runs and change settings\n",
    "import wandb\n",
    "\n",
    "# Replace the variables below with your own: name, project name, and project directory\n",
    "%env WANDB_ENTITY = langdon\n",
    "%env WANDB_PROJECT = ellipse\n",
    "%env WANDB_DIR = /home/jovyan/active-projects/ellipse-methods-showcase/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177080b1-2717-4ae0-b856-f72844c625eb",
   "metadata": {},
   "source": [
    "## Load DatasetDict and Tokenize\n",
    "\n",
    "We could have tokenized our datadict when we created the dataset partitions, but waiting until the last minute gives us the flexibility to try out different models that may require different tokenization schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e9e764f-e78c-412c-b04a-dd91968dc978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize tokenizer and create helper function for tokenization as we did in the previous notebooks.\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_inputs(example):\n",
    "    return tokenizer(example['text'], max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a87615f-8e33-45a8-b10d-daf0812d4b20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_datadict(score_to_predict):\n",
    "    ''' Selects a target score that the model should predict and renames that score to 'label'.\n",
    "    Removes other columns from the dataset. The other columns are not needed for training.\n",
    "    '''\n",
    "    \n",
    "    # These columns will be removed from the dataset\n",
    "    scores = {\n",
    "        'Overall',\n",
    "        'Cohesion',\n",
    "        'Syntax',\n",
    "        'Vocabulary',\n",
    "        'Phraseology',\n",
    "        'Grammar',\n",
    "        'Conventions'\n",
    "    }\n",
    "    \n",
    "    columns_to_remove = scores.symmetric_difference([score_to_predict])\n",
    "    \n",
    "    # Load the DatasetDict object we created in the previous notebook. \n",
    "    # We will be removing the columns that we defined above, and renaming the target column (=score_to_predict) into 'label'\n",
    "    dd = (DatasetDict\n",
    "          .load_from_disk('../data/ellipse.hf')\n",
    "          .remove_columns(columns_to_remove)\n",
    "          .map(tokenize_inputs, remove_columns=['text_id', 'text']) # the transformer does not need these columns to train.\n",
    "          .rename_column(score_to_predict, 'label') # Huggingface will look for a column that contains the string 'label' to calculate metrics.\n",
    "         )\n",
    "    \n",
    "    return dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3346da08-38c8-440d-a0ef-27759050db9d",
   "metadata": {},
   "source": [
    "## Compute Metric\n",
    "\n",
    "By default, Huggingface will evaluate models based on the sum of metrics produced by this function.\n",
    "\n",
    "We only have one metric (mse), but if other metrics are included (like r-squared), Huggingface needs to know which metric to use (because MSE should be minimized and r-squared should be maximized, summing these values will create a nonsense metric). We will be specifying th metric when we are configuring the training arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b56260e-022b-4655-abdc-8324332ae0c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    mse = mean_squared_error(labels, preds)\n",
    "\n",
    "    return {'mse': mse}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27719516-3918-44b6-b734-b9599b9e4a31",
   "metadata": {},
   "source": [
    "## Train Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9aef09b1-3ce9-42ff-ad4c-a60ea6ec9266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(score_to_predict):\n",
    "    # since we create the model from_pretrained() within the train() function, we do not need a model_init()\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n",
    "    \n",
    "    # load in the dataset we created before with the target column's name changed to 'label'\n",
    "    datadict = get_datadict(score_to_predict)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = f'../bin/{score_to_predict.lower()}-checkpoints',\n",
    "        optim = 'adamw_torch',\n",
    "        logging_dir = f'../logs/{score_to_predict}',\n",
    "        load_best_model_at_end = True,\n",
    "        metric_for_best_model = 'mse', # be sure to set this value if compute_metrics returns multiple metrics.\n",
    "        evaluation_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        save_total_limit=1, # only keep the best model\n",
    "        greater_is_better = False,\n",
    "        log_level = 'error',\n",
    "        disable_tqdm = False,\n",
    "        report_to='wandb',\n",
    "        num_train_epochs=2, # tuned\n",
    "        learning_rate=5e-5, # tuned\n",
    "        per_device_train_batch_size=16, # tuned\n",
    "        per_device_eval_batch_size=16,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=datadict['train'],\n",
    "        eval_dataset=datadict['dev'],\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "    return trainer    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ca5e4-f0b5-4255-b0e3-70001d125a07",
   "metadata": {},
   "source": [
    "## Train Grammar\n",
    "\n",
    "Finetune a model that predicts the 'Grammar' scores in the ELLIPSE corpus using the function we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "943296c0-bc44-4bec-ab9c-80c7269ff12d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4537 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/973 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='568' max='568' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [568/568 04:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256704</td>\n",
       "      <td>0.256704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.353500</td>\n",
       "      <td>0.239764</td>\n",
       "      <td>0.239764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grammar_trainer = train('Grammar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed367c-583c-4acd-a0ed-599694e6eb19",
   "metadata": {},
   "source": [
    "## Train Vocabulary\n",
    "\n",
    "We can use the same approach to finetune a model that predicts the 'Vocabulary' scores. We will assume that the optimal hyperparameters are similar for different scores on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "267b472f-34cb-4c26-87a6-648e24e6fa07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4537 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/973 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='568' max='568' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [568/568 04:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.210288</td>\n",
       "      <td>0.210288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.288800</td>\n",
       "      <td>0.211494</td>\n",
       "      <td>0.211494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_trainer = train('Vocabulary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a0868-45c4-4596-81fd-48fd8c613b47",
   "metadata": {},
   "source": [
    "## Save\n",
    "\n",
    "These models were automatically saved to '../bin/{score_to_predict}/' but we can give them better names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fe18edd-d321-401b-9429-3d3941db24db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grammar_trainer.save_model('../bin/grammar-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1781d17b-3212-4cd4-a444-8c92408cbce4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_trainer.save_model('../bin/vocabulary-model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
