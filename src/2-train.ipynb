{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1493d6bd-0e19-420a-b63a-83df30f82cc9",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "In this notebook, we will train 2 models using the best hyperparameters for this dataset.\n",
    "\n",
    "We will continue to use the wandb library to track our training runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "730a553a-0c6f-4ee3-a63d-b71cdcf4c121",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_ENTITY=langdon\n",
      "env: WANDB_PROJECT=ellipse\n",
      "env: WANDB_DIR=/home/jovyan/active-projects/ellipse-methods-showcase/bin\n"
     ]
    }
   ],
   "source": [
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer, DefaultDataCollator)\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import wandb\n",
    "%env WANDB_ENTITY = langdon\n",
    "%env WANDB_PROJECT = ellipse\n",
    "%env WANDB_DIR = /home/jovyan/active-projects/ellipse-methods-showcase/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177080b1-2717-4ae0-b856-f72844c625eb",
   "metadata": {},
   "source": [
    "## Load DatasetDict and Tokenize\n",
    "\n",
    "We could have tokenized our datadict when we created the dataset partitions, but waiting until the last minute gives us the flexibility to try out different models that may require different tokenization schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e9e764f-e78c-412c-b04a-dd91968dc978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_inputs(example):\n",
    "    return tokenizer(example['text'], max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a87615f-8e33-45a8-b10d-daf0812d4b20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_datadict(score_to_predict):\n",
    "    ''' Selects a target score that the model should predict and renames that score to 'label'.\n",
    "    Removes other columns from the dataset. The other columns are not needed for training.\n",
    "    '''\n",
    "    \n",
    "    scores = {\n",
    "        'Overall',\n",
    "        'Cohesion',\n",
    "        'Syntax',\n",
    "        'Vocabulary',\n",
    "        'Phraseology',\n",
    "        'Grammar',\n",
    "        'Conventions'\n",
    "    }\n",
    "    \n",
    "    columns_to_remove = scores.symmetric_difference([score_to_predict])\n",
    "    \n",
    "    dd = (DatasetDict\n",
    "          .load_from_disk('../data/ellipse.hf')\n",
    "          .remove_columns(columns_to_remove)\n",
    "          .map(tokenize_inputs, remove_columns=['text_id', 'text']) # the transformer does not need these columns to train.\n",
    "          .rename_column(score_to_predict, 'label') # Huggingface will look for a column that contains the string 'label' to calculate metrics.\n",
    "         )\n",
    "    \n",
    "    return dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3346da08-38c8-440d-a0ef-27759050db9d",
   "metadata": {},
   "source": [
    "## Compute Metric\n",
    "\n",
    "By default, Huggingface will evaluate models based on the sum of metrics produced by this function.\n",
    "\n",
    "We only have one metric (mse), but if other metrics are included (like r-squared), Huggingface needs to know which metric to use (because MSE should be minimized and r-squared should be maximized, summing these values will create a nonsense metric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b56260e-022b-4655-abdc-8324332ae0c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    mse = mean_squared_error(labels, preds)\n",
    "\n",
    "    return {'mse': mse}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27719516-3918-44b6-b734-b9599b9e4a31",
   "metadata": {},
   "source": [
    "## Train Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9aef09b1-3ce9-42ff-ad4c-a60ea6ec9266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(score_to_predict):\n",
    "    # since we create the model from_pretrained() within the train() function, we do not need a model_init()\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n",
    "    \n",
    "    datadict = get_datadict(score_to_predict)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = f'../bin/{score_to_predict}',\n",
    "        optim = 'adamw_torch',\n",
    "        logging_dir = f'../logs/{score_to_predict}',\n",
    "        load_best_model_at_end = True,\n",
    "        metric_for_best_model = 'mse', # be sure to set this value if compute_metrics returns multiple metrics.\n",
    "        evaluation_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        save_total_limit=1, # only keep the best model\n",
    "        greater_is_better = False,\n",
    "        log_level = 'error',\n",
    "        disable_tqdm = False,\n",
    "        report_to='wandb',\n",
    "        num_train_epochs=2, # tuned\n",
    "        learning_rate=5e-5, # tuned\n",
    "        per_device_train_batch_size=16, # tuned\n",
    "        per_device_eval_batch_size=16,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=datadict['train'],\n",
    "        eval_dataset=datadict['dev'],\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "    return trainer    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ca5e4-f0b5-4255-b0e3-70001d125a07",
   "metadata": {},
   "source": [
    "## Train Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "943296c0-bc44-4bec-ab9c-80c7269ff12d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4537 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/973 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='568' max='568' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [568/568 04:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256704</td>\n",
       "      <td>0.256704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.353500</td>\n",
       "      <td>0.239764</td>\n",
       "      <td>0.239764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grammar_trainer = train('Grammar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed367c-583c-4acd-a0ed-599694e6eb19",
   "metadata": {},
   "source": [
    "## Train Vocabulary\n",
    "\n",
    "We will assume that the optimal hyperparameters are similar for different scores on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b472f-34cb-4c26-87a6-648e24e6fa07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4537 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/973 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='285' max='568' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [285/568 02:07 < 02:07, 2.22 it/s, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/61 00:03 < 00:05, 7.06 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_trainer = train('Vocabulary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c120ae70-a44c-4b8a-b16f-f729cde6a13f",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d85e57-7f13-401a-9612-0eac8107e36e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ellipse]",
   "language": "python",
   "name": "conda-env-ellipse-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
